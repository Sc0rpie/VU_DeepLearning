{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNfQoWib3mk8LADYKzYzqtP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sc0rpie/VU_DeepLearning/blob/main/Lab1_updated.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pirmas laboratorinis darbas\n",
        "\n",
        "Olen Račkauskas, 3 grupė, 2 pogrupis, 2213787 (VGG16)\n",
        "\n",
        "Klasifikuojamos klasės: Orange, Banana, Strawberry"
      ],
      "metadata": {
        "id": "9ej25kydnhlC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXo-9KUwAdqH",
        "outputId": "434ed653-447c-42e2-a3f4-6eb2fe9a0bce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openimages\n",
            "  Downloading openimages-0.0.1-py2.py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting boto3 (from openimages)\n",
            "  Downloading boto3-1.36.26-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting cvdata (from openimages)\n",
            "  Downloading cvdata-0.0.3-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from openimages) (5.3.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from openimages) (2.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from openimages) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openimages) (4.67.1)\n",
            "Collecting botocore<1.37.0,>=1.36.26 (from boto3->openimages)\n",
            "  Downloading botocore-1.36.26-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3->openimages)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.12.0,>=0.11.0 (from boto3->openimages)\n",
            "  Downloading s3transfer-0.11.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from cvdata->openimages) (1.26.4)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from cvdata->openimages) (4.11.0.86)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from cvdata->openimages) (11.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->openimages) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->openimages) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->openimages) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->openimages) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->openimages) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->openimages) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->openimages) (2025.1.31)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->openimages) (1.17.0)\n",
            "Downloading openimages-0.0.1-py2.py3-none-any.whl (10 kB)\n",
            "Downloading boto3-1.36.26-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cvdata-0.0.3-py3-none-any.whl (37 kB)\n",
            "Downloading botocore-1.36.26-py3-none-any.whl (13.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m94.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading s3transfer-0.11.2-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.2/84.2 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jmespath, botocore, s3transfer, boto3, cvdata, openimages\n",
            "Successfully installed boto3-1.36.26 botocore-1.36.26 cvdata-0.0.3 jmespath-1.0.1 openimages-0.0.1 s3transfer-0.11.2\n"
          ]
        }
      ],
      "source": [
        "!pip install openimages"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from torchvision import models, transforms, datasets\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "x-KaERZ_A5jm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Atsiunčiamos nuotraukos (300 Orange ir Banana, 400 Strawberry = 1000)"
      ],
      "metadata": {
        "id": "SN04y6dY6xPB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"data\"\n",
        "number_for_samples = 300\n",
        "classes_to_download = [\"Orange\", \"Banana\"]\n",
        "if not os.path.exists(data_dir):\n",
        "    os.mkdir(data_dir)\n",
        "\n",
        "print(\"Download commencing...\")\n",
        "from openimages.download import download_dataset\n",
        "download_dataset(data_dir, classes_to_download, limit=number_for_samples)\n",
        "download_dataset(data_dir, [\"Strawberry\"], limit=400)\n",
        "print(\"Download finished.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fE8eohXiA1P_",
        "outputId": "c30c5e26-3e03-4320-bb2e-508f690beb18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download commencing...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [00:19<00:00, 15.08it/s]\n",
            "100%|██████████| 300/300 [00:18<00:00, 15.86it/s]\n",
            "100%|██████████| 400/400 [00:25<00:00, 15.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sukomponuojam transformacijas bei panaudojam jau aprašyta DataSet: ImageFolder\n",
        "\n",
        "Prie to pačio patikrinam ar turim 1000 nuotraukų"
      ],
      "metadata": {
        "id": "nxWuIoux689W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "dataset = datasets.ImageFolder(root=data_dir, transform=all_transforms)\n",
        "print(f\"Dataset size: {len(dataset)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8lxp0ocBAm5",
        "outputId": "44d74cbc-4e88-4065-d71b-c64425483f32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset size: 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paruošiamas DataLoader bei peržiūrimas klasių mapping'as"
      ],
      "metadata": {
        "id": "zGye4NOT7WDe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loader = DataLoader(dataset, batch_size=64, shuffle=True, num_workers=2)\n",
        "\n",
        "classes = sorted(os.listdir('data'))\n",
        "class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}\n",
        "print(\"Class to index mapping:\", class_to_idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UWaLawHBEvW",
        "outputId": "378ae5dd-b83f-4367-d47f-859420893327"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class to index mapping: {'banana': 0, 'orange': 1, 'strawberry': 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paruošiamas VGG16 modelis naudojimui"
      ],
      "metadata": {
        "id": "Omb4Etw-7eU6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.vgg16(pretrained=True)\n",
        "model.to(\"cuda\")\n",
        "model.eval();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XY6yUlDoBWKy",
        "outputId": "88bd26a8-96f1-4c93-8458-54081f13fff5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:07<00:00, 77.5MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aprašomos klasių ID iš imagenet 1000 klasių sąrašo"
      ],
      "metadata": {
        "id": "D5AVNVzF7joR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_to_imagenet = {\n",
        "    0: 954,   # \"Banana\"\n",
        "    1: 950,   # \"Orange\"\n",
        "    2: 949    # \"Strawberry\"\n",
        "}"
      ],
      "metadata": {
        "id": "FrICX0emBe56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Aprašomos funkcijos skaičiavimams"
      ],
      "metadata": {
        "id": "ExasSxJv8sgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(ground_truth, predictions, threshold=0.5):\n",
        "    pred_bin = (predictions > threshold).astype(np.float64)\n",
        "    TP = np.sum((ground_truth == 1) & (pred_bin == 1))\n",
        "    TN = np.sum((ground_truth == 0) & (pred_bin == 0))\n",
        "    FP = np.sum((ground_truth == 0) & (pred_bin == 1))\n",
        "    FN = np.sum((ground_truth == 1) & (pred_bin == 0))\n",
        "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
        "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0.0\n",
        "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0.0\n",
        "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
        "    return {'accuracy': accuracy, 'recall': recall, 'precision': precision, 'f1': f1}\n",
        "\n",
        "def get_class_predictions(prob_array, labels, imagenet_class_index, dataset_label):\n",
        "    gt = (labels == dataset_label).astype(np.float64)\n",
        "    pred = prob_array[:, imagenet_class_index]\n",
        "    return gt, pred"
      ],
      "metadata": {
        "id": "Hm_HeLFWBiDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paleidžiamas modelis, įrašomos visos tikimybės į masyvą"
      ],
      "metadata": {
        "id": "l_6dGcNh8xkk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_probabilities = []\n",
        "all_labels = []\n",
        "\n",
        "for images, labels in loader:\n",
        "    images, labels = images.cuda(), labels.cuda()\n",
        "    outputs = model(images)\n",
        "    probabilities = torch.softmax(outputs, dim=1).detach().cpu().numpy()\n",
        "    all_probabilities.append(probabilities)\n",
        "    all_labels.append(labels.cpu().numpy())\n",
        "\n",
        "all_probabilities = np.concatenate(all_probabilities, axis=0)\n",
        "all_labels = np.concatenate(all_labels, axis=0)"
      ],
      "metadata": {
        "id": "W9jRjn70Bkb2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gauti rezultatai naudojami skaičiavimams ir rezultato atvaizdavimui"
      ],
      "metadata": {
        "id": "k5paTsEg87Ue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metrics_results = {}\n",
        "for dataset_label, imagenet_idx in dataset_to_imagenet.items():\n",
        "    gt, pred = get_class_predictions(all_probabilities, all_labels, imagenet_idx, dataset_label)\n",
        "    metrics = compute_metrics(gt, pred, threshold=0.4)\n",
        "    class_name = list(class_to_idx.keys())[list(class_to_idx.values()).index(dataset_label)]\n",
        "    metrics_results[class_name] = metrics\n",
        "\n",
        "for class_name, metrics in metrics_results.items():\n",
        "    print(f\"{class_name} metrics: {metrics}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rs5CZdF4BnKX",
        "outputId": "f1f608a6-b13f-446f-ee0f-dc4d04b6dcda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "banana metrics: {'accuracy': 0.879, 'recall': 0.5966666666666667, 'precision': 1.0, 'f1': 0.7473903966597077}\n",
            "orange metrics: {'accuracy': 0.81, 'recall': 0.37333333333333335, 'precision': 0.9824561403508771, 'f1': 0.5410628019323672}\n",
            "strawberry metrics: {'accuracy': 0.769, 'recall': 0.4225, 'precision': 1.0, 'f1': 0.5940246045694201}\n"
          ]
        }
      ]
    }
  ]
}