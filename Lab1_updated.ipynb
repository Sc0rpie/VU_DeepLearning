{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyODuO0I2KEi92fqHV5bd00I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sc0rpie/VU_DeepLearning/blob/main/Lab1_updated.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pirmas laboratorinis darbas\n",
        "\n",
        "Olen Račkauskas, 3 grupė, 2 pogrupis, 2213787 (VGG16)\n",
        "\n",
        "Klasifikuojamos klasės: Orange, Banana, Strawberry"
      ],
      "metadata": {
        "id": "9ej25kydnhlC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXo-9KUwAdqH",
        "outputId": "c3e80d53-eabb-4695-e332-dae6a2262afe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openimages\n",
            "  Downloading openimages-0.0.1-py2.py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting boto3 (from openimages)\n",
            "  Downloading boto3-1.37.1-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting cvdata (from openimages)\n",
            "  Downloading cvdata-0.0.3-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from openimages) (5.3.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from openimages) (2.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from openimages) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openimages) (4.67.1)\n",
            "Collecting botocore<1.38.0,>=1.37.1 (from boto3->openimages)\n",
            "  Downloading botocore-1.37.1-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3->openimages)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.12.0,>=0.11.0 (from boto3->openimages)\n",
            "  Downloading s3transfer-0.11.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from cvdata->openimages) (1.26.4)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from cvdata->openimages) (4.11.0.86)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from cvdata->openimages) (11.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->openimages) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->openimages) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->openimages) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->openimages) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->openimages) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->openimages) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->openimages) (2025.1.31)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->openimages) (1.17.0)\n",
            "Downloading openimages-0.0.1-py2.py3-none-any.whl (10 kB)\n",
            "Downloading boto3-1.37.1-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cvdata-0.0.3-py3-none-any.whl (37 kB)\n",
            "Downloading botocore-1.37.1-py3-none-any.whl (13.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading s3transfer-0.11.2-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.2/84.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jmespath, botocore, s3transfer, boto3, cvdata, openimages\n",
            "Successfully installed boto3-1.37.1 botocore-1.37.1 cvdata-0.0.3 jmespath-1.0.1 openimages-0.0.1 s3transfer-0.11.2\n"
          ]
        }
      ],
      "source": [
        "!pip install openimages"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from torchvision import models, transforms, datasets\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "x-KaERZ_A5jm"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Atsiunčiamos nuotraukos (300 Orange ir Banana, 400 Strawberry = 1000)"
      ],
      "metadata": {
        "id": "SN04y6dY6xPB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"data\"\n",
        "number_for_samples = 300\n",
        "classes_to_download = [\"Orange\", \"Banana\"]\n",
        "if not os.path.exists(data_dir):\n",
        "    os.mkdir(data_dir)\n",
        "\n",
        "print(\"Download commencing...\")\n",
        "from openimages.download import download_dataset\n",
        "download_dataset(data_dir, classes_to_download, limit=number_for_samples)\n",
        "download_dataset(data_dir, [\"Strawberry\"], limit=400)\n",
        "print(\"Download finished.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fE8eohXiA1P_",
        "outputId": "fb30120d-293e-4194-ff3d-6b9d0253169c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download commencing...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [00:08<00:00, 36.51it/s]\n",
            "100%|██████████| 300/300 [00:07<00:00, 39.18it/s]\n",
            "100%|██████████| 400/400 [00:10<00:00, 39.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sukomponuojam transformacijas bei panaudojam jau aprašyta DataSet: ImageFolder\n",
        "\n",
        "Prie to pačio patikrinam ar turim 1000 nuotraukų"
      ],
      "metadata": {
        "id": "nxWuIoux689W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225]),\n",
        "])"
      ],
      "metadata": {
        "id": "u8lxp0ocBAm5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, root, transform=None):\n",
        "        self.root = root\n",
        "        self.transform = transform\n",
        "        self.samples = []\n",
        "\n",
        "        self.classes = sorted(\n",
        "            [d for d in os.listdir(root) if os.path.isdir(os.path.join(root, d))]\n",
        "        )\n",
        "\n",
        "        self.class_to_idx = {cls_name: idx for idx, cls_name in enumerate(self.classes)}\n",
        "\n",
        "        for cls in self.classes:\n",
        "            cls_folder = os.path.join(root, cls)\n",
        "            for root_dir, _, files in os.walk(cls_folder):\n",
        "                for file in files:\n",
        "                    if file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
        "                        path = os.path.join(root_dir, file)\n",
        "                        self.samples.append((path, self.class_to_idx[cls]))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image_path, label = self.samples[index]\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "FteJeTr3FKR0"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = MyDataset(root=data_dir, transform=all_transforms)\n",
        "print(f\"Dataset size: {len(dataset)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2MLowVlFONR",
        "outputId": "2359d5c0-b38a-4443-d9da-2ac35310e44e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset size: 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paruošiamas DataLoader bei peržiūrimas klasių mapping'as"
      ],
      "metadata": {
        "id": "zGye4NOT7WDe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loader = DataLoader(dataset, batch_size=64, shuffle=True, num_workers=2)\n",
        "\n",
        "classes = sorted(os.listdir('data'))\n",
        "class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}\n",
        "print(\"Class to index mapping:\", class_to_idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UWaLawHBEvW",
        "outputId": "410dd9b1-1c20-47f0-fc1b-4757303fae6b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class to index mapping: {'banana': 0, 'orange': 1, 'strawberry': 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paruošiamas VGG16 modelis naudojimui"
      ],
      "metadata": {
        "id": "Omb4Etw-7eU6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.vgg16(pretrained=True)\n",
        "model.to(\"cuda\")\n",
        "model.eval();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XY6yUlDoBWKy",
        "outputId": "963402ba-7a91-48e7-ca21-5729d437c29b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:03<00:00, 161MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aprašomos klasių ID iš imagenet 1000 klasių sąrašo"
      ],
      "metadata": {
        "id": "D5AVNVzF7joR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_to_imagenet = {\n",
        "    0: 954,   # \"Banana\"\n",
        "    1: 950,   # \"Orange\"\n",
        "    2: 949    # \"Strawberry\"\n",
        "}"
      ],
      "metadata": {
        "id": "FrICX0emBe56"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aprašomos funkcijos skaičiavimams"
      ],
      "metadata": {
        "id": "JWPtBaHtvAcX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(ground_truth, predictions, threshold=0.5):\n",
        "    pred_bin = (predictions > threshold).astype(np.float64)\n",
        "    TP = np.sum((ground_truth == 1) & (pred_bin == 1))\n",
        "    TN = np.sum((ground_truth == 0) & (pred_bin == 0))\n",
        "    FP = np.sum((ground_truth == 0) & (pred_bin == 1))\n",
        "    FN = np.sum((ground_truth == 1) & (pred_bin == 0))\n",
        "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
        "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0.0\n",
        "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0.0\n",
        "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
        "    return {'accuracy': accuracy, 'recall': recall, 'precision': precision, 'f1': f1}\n",
        "\n",
        "def get_class_predictions(prob_array, labels, imagenet_class_index, dataset_label):\n",
        "    gt = (labels == dataset_label).astype(np.float64)\n",
        "    pred = prob_array[:, imagenet_class_index]\n",
        "    return gt, pred"
      ],
      "metadata": {
        "id": "Hm_HeLFWBiDi"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paleidžiamas modelis, įrašomos visos tikimybės į masyvą"
      ],
      "metadata": {
        "id": "l_6dGcNh8xkk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_probabilities = []\n",
        "all_labels = []\n",
        "\n",
        "for images, labels in loader:\n",
        "    images, labels = images.cuda(), labels.cuda()\n",
        "    outputs = model(images)\n",
        "    probabilities = torch.sigmoid(outputs).detach().cpu().numpy()\n",
        "    all_probabilities.append(probabilities)\n",
        "    all_labels.append(labels.cpu().numpy())\n",
        "\n",
        "all_probabilities = np.concatenate(all_probabilities, axis=0)\n",
        "all_labels = np.concatenate(all_labels, axis=0)"
      ],
      "metadata": {
        "id": "W9jRjn70Bkb2"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gauti rezultatai naudojami skaičiavimams ir rezultato atvaizdavimui"
      ],
      "metadata": {
        "id": "k5paTsEg87Ue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metrics_results = {}\n",
        "for dataset_label, imagenet_idx in dataset_to_imagenet.items():\n",
        "    gt, pred = get_class_predictions(all_probabilities, all_labels, imagenet_idx, dataset_label)\n",
        "    metrics = compute_metrics(gt, pred, threshold=0.95)\n",
        "    class_name = list(class_to_idx.keys())[list(class_to_idx.values()).index(dataset_label)]\n",
        "    metrics_results[class_name] = metrics\n",
        "\n",
        "for class_name, metrics in metrics_results.items():\n",
        "    print(f\"{class_name} metrics: {metrics}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rs5CZdF4BnKX",
        "outputId": "e7b96fab-c7be-4d4e-8a7b-bc9442f59eae"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "banana metrics: {'accuracy': 0.333, 'recall': 0.9766666666666667, 'precision': 0.3074501573976915, 'f1': 0.4676775738228252}\n",
            "orange metrics: {'accuracy': 0.35, 'recall': 0.97, 'precision': 0.31223175965665234, 'f1': 0.4724025974025974}\n",
            "strawberry metrics: {'accuracy': 0.618, 'recall': 0.9925, 'precision': 0.5115979381443299, 'f1': 0.6751700680272107}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nuotrauku patikrinimui"
      ],
      "metadata": {
        "id": "EdwAArnSARQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "def predict_images(image_paths, model, transform, device=\"cuda\"):\n",
        "    if isinstance(image_paths, str):\n",
        "        image_paths = [image_paths]\n",
        "\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "\n",
        "    for path in image_paths:\n",
        "        try:\n",
        "            img = Image.open(path).convert(\"RGB\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading image {path}: {e}\")\n",
        "            continue\n",
        "\n",
        "        input_tensor = transform(img).unsqueeze(0).to(device)\n",
        "\n",
        "        # Inference.\n",
        "        with torch.no_grad():\n",
        "            outputs = model(input_tensor)\n",
        "            probs = torch.sigmoid(outputs).cpu().numpy()[0]\n",
        "\n",
        "        predictions.append(probs)\n",
        "\n",
        "    return predictions"
      ],
      "metadata": {
        "id": "oF4r-DTRAQ5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def print_top_predictions(pred_vector, topk=5):\n",
        "    top_indices = np.argsort(pred_vector)[::-1][:topk]\n",
        "    print(\"Top predictions:\")\n",
        "    for idx in top_indices:\n",
        "        print(f\"  Class id {idx}: probability {pred_vector[idx]:.4f}\")"
      ],
      "metadata": {
        "id": "iJHSl_cbBJ1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_files = [\"data/gmm.jpg\"]\n",
        "preds = predict_images(image_files, model, all_transforms, device=\"cuda\")\n",
        "print_top_predictions(preds[0], topk=5)"
      ],
      "metadata": {
        "id": "hqRRuW35AXzS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}